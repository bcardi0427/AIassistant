{
  "config": {
    "step": {
      "user": {
        "title": "AIassistant",
        "description": "Select your AI provider to get started.",
        "data": {
          "provider": "AI Provider"
        }
      },
      "credentials": {
        "title": "Connect to {provider}",
        "description": "Enter your API credentials. We'll fetch available models automatically.",
        "data": {
          "api_url": "API URL (leave empty for default)",
          "api_key": "API Key"
        }
      },
      "configure": {
        "title": "Configure {provider}",
        "description": "Found {models_count} models. Select your model and configure options.",
        "data": {
          "model": "Model",
          "log_level": "Log Level",
          "temperature": "Temperature (optional)",
          "system_prompt_file": "System Prompt File (optional)",
          "enable_cache_control": "Enable Cache Control",
          "usage_tracking": "Usage Tracking Method"
        }
      }
    },
    "error": {
      "cannot_connect": "Failed to connect to the API. Please check your API key and URL.",
      "unknown": "An unexpected error occurred."
    },
    "abort": {
      "already_configured": "AIassistant is already configured."
    }
  },
  "options": {
    "step": {
      "init": {
        "title": "AIassistant Options",
        "description": "Models available: {models_count}",
        "data": {
          "provider": "AI Provider",
          "api_url": "API URL",
          "api_key": "API Key",
          "model": "Model",
          "log_level": "Log Level",
          "temperature": "Temperature (optional)",
          "system_prompt_file": "System Prompt File (optional)",
          "enable_cache_control": "Enable Cache Control",
          "usage_tracking": "Usage Tracking Method"
        }
      }
    }
  },
  "selector": {
    "provider": {
      "options": {
        "openai": "OpenAI",
        "gemini": "Google Gemini",
        "anthropic": "Anthropic (Claude)",
        "openrouter": "OpenRouter",
        "ollama": "Ollama (Local)",
        "custom": "Custom Provider"
      }
    }
  }
}